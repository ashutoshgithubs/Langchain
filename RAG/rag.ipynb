{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f73c4001",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Ingestion -> bringing data from different sources into one place \n",
    "### From txt file\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"speech.txt\")\n",
    "text_docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4a737ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The world must be made safe for democracy. Its peace must be planted upon the tested foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no dominion. We seek no indemnities for ourselves, no material compensation for the sacrifices we shall freely make. We are but one of the champions of the rights of mankind. We shall be satisfied when those rights have been made as secure as the faith and the freedom of nations can make them.\\n\\nJust because we fight withou'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_docs[0].page_content[:500]  # first 500 characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd76ab50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "## From Web \n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "# loader = WebBaseLoader(\n",
    "#     web_paths=(\"https://medium.com/@ashubhai/webrtc-applications-with-node-js-and-react-js-7f4d4313bace\",),\n",
    "#     bs_kwargs=dict(\n",
    "#         parse_only=bs4.SoupStrainer(\n",
    "#             class_=(\"pw-post-title\",\"pw-post-body\") \n",
    "#         )\n",
    "#     )\n",
    "# )\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://medium.com/@ashubhai/webrtc-applications-with-node-js-and-react-js-7f4d4313bace\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"p\"  \n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "web_docs = loader.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f39894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(Web Real-Time Communication) is a groundbreaking technology enabling real-time multi-media communication within web browsers. By eliminating the need for third-party plugins or software, it facilitates seamless, efficient, and accessible browser-based interactions. In this article, we’ll explore how WebRTC works, its core components, and implement a real-time communication application using Node.js as the signaling server and React.js for the frontend.3. Open Standard:WebRTC’s open standard ensures compatibility across major browsers and platforms, encouraging widespread adoption.The above image shows two browsers directly connected to each other in a P2P mode. In a WebRTC P2P connection, media data (audio, video, etc.) is transmitted directly between the two peers without going through an intermediary server. This direct connection enhances efficiency and reduces latency.While media data is transmitted directly between peers, WebRTC requires certain servers for specific tasks like signaling, NAT traversal, and media handling.2. Signaling Server:This facilitates the initial handshake between peers, exchanging metadata and connection details like IPs. It is implemented using Web-Socket or HTTP.3. STUN and TURN Servers:The above image shows two browsers communicating through a STUN server and a signaling server. The STUN server helps determine the public IP addresses of the peers, which is crucial for establishing a direct P2P connection, especially when the peers are behind Network Address Translation (NAT) devices like routers.STUN can bridge P2P connections for most NATs except the few cases where it has unpredictable port mapping. In such cases, the two peers simply cannot talk 1-on-1 directly, and all their traffic is relayed through a TURN server. TURN stands for Traversal Using Relay NAT that has public addresses, so they can be contacted by peers even if the peers are behind firewalls or proxies. It can be used as a fallback, relaying audio/video/data streaming between peers just like a traditional media server-based architecture.4. ICE Candidates:Represents potential connection endpoints. Browsers exchange ICE candidates to finalize the best connection path.5. Offer and Answer Model:Establishing a WebRTC connection between two peers involves a series of steps facilitated by the signaling server and the RTCPeerConnection API provided by the browser. Here’s a breakdown of the process:At this point, the WebRTC connection is established between the two peers, and they can start exchanging media data directly in a peer-to-peer fashion.To actually send and receive media (audio and video), additional steps are required:To build a WebRTC application, we will utilize Node.js to set up the signaling server and React on the frontend, leveraging the RTCPeerConnection API for real-time communication.The signaling server will be built using Node.js and will act as a WebSocket server to facilitate the exchange of signaling messages between the peers. It will support three types of messages:2. Frontend with React.jsEstablishing the WebRTC Connection:Exchanging ICE Candidates:Sending and Receiving Media:Access the Full Code Repository: WebRTCWebRTC offers a robust framework for real-time peer-to-peer communication, but implementing it from scratch can be complex due to extensive boilerplate code. Thankfully, third-party libraries like PeerJS streamline this process. PeerJS abstracts the complexity of establishing WebRTC connections, providing developers with a user-friendly API. This allows you to focus on building your application’s core logic while leaving the intricate details of WebRTC to the library.While P2P communication is excellent for one-on-one or small group calls, it faces significant challenges when scaling to larger groups:To overcome these limitations, alternative architectures like SFU and MCU are commonly used in WebRTC implementations:These architectures address the scalability and performance challenges of P2P and are better suited for large-scale applications. We’ll discuss these architectures, their advantages, and real-world use cases in a separate article.WebRTC opens up endless possibilities for real-time applications, from video conferencing to gaming. By combining Node.js for signaling and React.js for the frontend, we can efficiently harness WebRTC’s power to create dynamic and responsive communication platforms. Whether you’re building a one-to-one chat app or a multi-user video conferencing tool, WebRTC’s capabilities and ease of integration make it the perfect choice.Have questions or want to discuss WebRTC further? Feel free to reach out to me on X !----A Full stack developer from India.HelpStatusAboutCareersPressBlogPrivacyRulesTermsText to speech'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_docs[0].page_content[48:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21bf0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## From PDF\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"attention.pdf\")\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f363ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Is All You Need Ashish Vaswani∗ Google Brain avaswani@google.com Noam Shazeer∗ Google Brain noam@google.com Niki Parmar∗ Google Research nikip@google.com Jakob Uszkoreit∗ Google Research usz@google.com Llion Jones∗ Google Research llion@google.com Aidan N. Gomez∗† University of Toronto aidan@cs.toronto.edu Łukasz Kaiser ∗ Google Brain lukaszkaiser@google.com Illia Polosukhin∗‡ illia.polosukhin@gmail.com Abstract The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English- to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. 1 Introduction Recurrent neural networks, long short-term memory [12] and gated recurrent [7] neural networks in particular, have been ﬁrmly established as state of the art approaches in sequence modeling and transduction problems such as language modeling and machine translation [ 29, 2, 5]. Numerous efforts have since continued to push the boundaries of recurrent language models and encoder-decoder architectures [31, 21, 13]. ∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started the effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head attention and the parameter-free position representation and became the other person involved in nearly every detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and efﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating our research. †Work performed while at Google Brain. ‡Work performed while at Google Research. 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = docs[0].page_content\n",
    "clean_text = re.sub(r'\\s+', ' ', text)  # collapse multiple spaces/newlines\n",
    "print(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0aaf2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets divide the documents into smaller chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e332823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Is All You Need Ashish Vaswani∗ Google Brain avaswani@google.com Noam Shazeer∗ Google Brain noam@google.com Niki Parmar∗ Google Research nikip@google.com Jakob Uszkoreit∗ Google Research usz@google.com Llion Jones∗ Google Research llion@google.com Aidan N. Gomez∗† University of Toronto aidan@cs.toronto.edu Łukasz Kaiser ∗ Google Brain lukaszkaiser@google.com Illia Polosukhin∗‡ illia.polosukhin@gmail.com Abstract The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = documents[0].page_content\n",
    "clean_text = re.sub(r'\\s+', ' ', text)  # collapse multiple spaces/newlines\n",
    "print(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1563b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vector Embedding And Vector Store\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "embeddings = OllamaEmbeddings(model=\"llama3.2:1b\")\n",
    "db = Chroma.from_documents(documents[:30],embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd3bacc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\n",
      "[20], ByteNet [15] and ConvS2S [8], all of which use convolutional neural networks as basic building\n",
      "block, computing hidden representations in parallel for all input and output positions. In these models,\n",
      "the number of operations required to relate signals from two arbitrary input or output positions grows\n",
      "in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\n",
      "it more difﬁcult to learn dependencies between distant positions [ 11]. In the Transformer this is\n",
      "reduced to a constant number of operations, albeit at the cost of reduced effective resolution due\n",
      "to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\n",
      "described in section 3.2.\n",
      "Self-attention, sometimes called intra-attention is an attention mechanism relating different positions\n"
     ]
    }
   ],
   "source": [
    "query = \"An attention function can be described as mapping a query\"\n",
    "retireved_results=db.similarity_search(query)\n",
    "print(retireved_results[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32b17d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Advance RAG : Retrievers and adding LLM\n",
    "from langchain_ollama import OllamaLLM\n",
    "llm = OllamaLLM(model=\"llama3.2:1b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "546eaf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Design prompt template \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the context provided.\n",
    "                                          Think step by step before proving the detailed answer.\n",
    "                                          I will tip you $1000 if the user find the answer satisfactory.\n",
    "                                          <context>\n",
    "                                          {context}\n",
    "                                          </context>\n",
    "                                          Question: {input}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da596dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chain Introduction -> Create Stuff document chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "doc_chain = create_stuff_documents_chain(llm,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7113bc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x00000214FF45D950>, search_kwargs={})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b09a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever chain -> doc_chain + retriever\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain = create_retrieval_chain(retriever,doc_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8c2c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"An attention function can be described as mapping a query and a set\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea35af17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An attention function in the context of neural networks can be described as mapping a query (usually represented by a vector) and a set of key vectors to a set of weighted values, where the weights are determined by the dot product of the query and the keys. The output is then normalized using the softmax function.\\n\\nIn more detail, an attention function typically consists of three main components:\\n\\n1. Query: This is the input that is being attended to.\\n2. Keys: These are vectors that represent the information being considered.\\n3. Values: These are weights or scores associated with each key vector.\\n\\nThe attention function can be represented mathematically as follows:\\n\\n`Attention Function = softmax( W * Q ) / sqrt(d)`\\n\\nWhere:\\n\\n* `W` is a weight matrix\\n* `Q` is the query vector\\n* `K` is the set of key vectors (usually represented by a matrix)\\n* `d` is the number of dimensions in the input space\\n\\nThe weights `W` are learned during training and can vary depending on the specific application. The softmax function is used to normalize the output, which means that it maps each value to a probability between 0 and 1.\\n\\nIt\\'s worth noting that the context provided mentions \"Multi-Head Attention\" as an alternative mechanism for computing hidden representations in parallel for all input and output positions. This suggests that attention functions can be used in different ways depending on the specific application, with Multi-Head Attention being one possible variation.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf234d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
